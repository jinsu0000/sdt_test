Filter the characters containing more than max_len points
number of training images:  50557
Filter the characters containing more than max_len points
Number of test images: 12634, Number of train images: 50557
Content_TR:: __init__ d_model: 512 , nhead: 2 , num_encoder_layers: 3 , dim_feedforward: 2048 , dropout: 0.1 , activation: relu , normalize_before: True
[TransformerDecoderLayer]: d_model=512, nhead=8, dim_feedforward=2048, dropout=0.1, activation=relu, normalize_before=True
TransformerDecoder:: __init__ decoder_layer: TransformerDecoderLayer(
  (self_attn): MultiheadAttention(
    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
  )
  (multihead_attn): MultiheadAttention(
    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
  )
  (linear1): Linear(in_features=512, out_features=2048, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
  (linear2): Linear(in_features=2048, out_features=512, bias=True)
  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout1): Dropout(p=0.1, inplace=False)
  (dropout2): Dropout(p=0.1, inplace=False)
  (dropout3): Dropout(p=0.1, inplace=False)
) , num_layers: 2 , norm: LayerNorm((512,), eps=1e-05, elementwise_affine=True) , return_intermediate: True
TransformerDecoder:: __init__ decoder_layer: TransformerDecoderLayer(
  (self_attn): MultiheadAttention(
    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
  )
  (multihead_attn): MultiheadAttention(
    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
  )
  (linear1): Linear(in_features=512, out_features=2048, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
  (linear2): Linear(in_features=2048, out_features=512, bias=True)
  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout1): Dropout(p=0.1, inplace=False)
  (dropout2): Dropout(p=0.1, inplace=False)
  (dropout3): Dropout(p=0.1, inplace=False)
) , num_layers: 2 , norm: LayerNorm((512,), eps=1e-05, elementwise_affine=True) , return_intermediate: True
/home/jinsu0000/anaconda3/envs/exp-sdt/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinsu0000/anaconda3/envs/exp-sdt/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
SDT_Generator::forward, style_imgs: torch.Size([16, 30, 1, 64, 64])
SDT_Generator::forward, batch_size: 16 , num_imgs: 30 , in_planes: 1 , h: 64 , w: 64
SDT_Generator::forward style_imgs.view(): torch.Size([480, 1, 64, 64])
SDT_Generator::forward Feat_Encoder_ResNet output: torch.Size([480, 512, 2, 2])
SDT_Generator::forward style_embe.view(): torch.Size([4, 480, 512])
SDT_Generator::forward base_encoder output memory: torch.Size([4, 480, 512])
SDT_Generator::forward WRITER memory: torch.Size([4, 480, 512]) , GLYPH memory: torch.Size([4, 480, 512])
SDT_Generator::forward rearrange writer_memory: torch.Size([4, 32, 15, 512]) , glyph_memory: torch.Size([4, 32, 15, 512])
SDT_Generator::forward [writer] memory_fea: torch.Size([60, 32, 512]) , compact_fea: torch.Size([32, 512])
SDT_Generator::forward [writer] pro_emb: torch.Size([32, 256])
SDT_Generator::forward [writer] query_emb: torch.Size([16, 256])
SDT_Generator::forward [writer] pos_emb: torch.Size([16, 256])
SDT_Generator::forward [writer] nce_emb: torch.Size([16, 2, 256])
SDT_Generator::forward [writer] normalize NCE nce_emb: torch.Size([16, 2, 256])
SDT_Generator::forward [glyph] patch_emb: torch.Size([4, 16, 15, 512])
SDT_Generator::forward [glyph] random_double_sampling result anc: torch.Size([16, 15, 1, 512]) , positive: torch.Size([16, 15, 1, 512]) , n_channels: 512
SDT_Generator::forward [glyph] anc reshape: torch.Size([16, 15, 512])
SDT_Generator::forward [glyph] anc_compact: torch.Size([16, 1, 512])
SDT_Generator::forward [glyph] anc_compact after pro_mlp_character: torch.Size([16, 1, 256])
SDT_Generator::forward [glyph] positive reshape: torch.Size([16, 15, 512])
SDT_Generator::forward [glyph] positive_compact: torch.Size([16, 1, 512])
SDT_Generator::forward [glyph] NCE anc_compact: torch.Size([16, 1, 256]) , positive_compact: torch.Size([16, 1, 256])
SDT_Generator::forward [glyph] normalize nce_emb_patch: torch.Size([16, 2, 256])
SDT_Generator::forward [KV] writer_style: torch.Size([60, 16, 512])
SDT_Generator::forward [KV] glyph_style: torch.Size([4, 16, 15, 512])
SDT_Generator::forward [KV] glyph_style rearranged: torch.Size([60, 16, 512])
SDT_Generator::forward [Decoder] seq: [16, T, 5] (T : length of the sequence)
SDT_Generator::forward [Decoder] seq_emb: [T, 16, 512]
Content_TR:: Feat_Encoder input: torch.Size([16, 1, 64, 64])
Content_TR:: Feat_Encoder Feat_Encoder(conv2d+resnet) output: torch.Size([16, 512, 2, 2])
Content_TR:: rearrange output: torch.Size([4, 16, 512])
Content_TR:: encoder output: torch.Size([4, 16, 512])
SDT_Generator::forward [Content Encoder] char_emb: [4, T, 16]
SDT_Generator::forward [Content Encoder] char_emb after mean: [T, 512]
SDT_Generator::forward [Content Encoder] char_emb after repeat: [1, T, 16]
SDT_Generator::forward [Decoder] tgt: [T, 16, 512] (T=T+1 : length of the sequence + 1 for content token)
generate_square_subsequent_mask: torch.Size([29, 29])
SDT_Generator::forward [Decoder] tgt after masking & add_position: [1+T, 16, 512]
[TransformerDecoder] *** forward: memory.shape=[1][B][torch.Size([60, 16, 512])], tgt.shape=[C][B][torch.Size([29, 16, 512])]
[TransformerDecoderLayer] *** forward_pre: memory.shape=[1][B][512], tgt.shape=[C][B][512]
[TransformerDecoderLayer] forward_pre tgt2.shape=[C][B][512] after self_attn
[TransformerDecoderLayer] forward_pre tgt.shape=[C][B][512] after sum with dropout1, norm2
[TransformerDecoderLayer] forward_pre tgt2.shape=[C][B][512] after multihead_attn
[TransformerDecoderLayer] *** forward_pre tgt.shape=[C][B][512] after linear
[TransformerDecoder] forward: layer[0] output.shape=[C][B][512]
[TransformerDecoder] forward: layer[1] output.shape=[C][B][512]
[TransformerDecoder] *** forward: output=[C][B][torch.Size([29, 16, 512])]
SDT_Generator::forward [Writer Decoder] wri_hs: 2, T, 16, 512] (wri_dec_layers, T, B, C)
SDT_Generator::forward [Glyph Decoder] hs: [2, T, 16, 512] (gly_dec_layers, T, B, C)
SDT_Generator::forward [Decoder] h after transpose: 16, T, 512] (B, T, C)
SDT_Generator::forward [Decoder Output] pred_sequence: [16, T, 123] (B, T, C)
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 29]), unique : tensor([   0,   13,   14,   17,   26,   27,   32,   36,   40,   42,   45,   48,
          49,   54,   56,   61,   67,   71,   77,   78,   81,   84,   87,   93,
          95,  106,  114,  117,  118,  127,  130,  132,  139,  144,  149,  152,
         157,  166,  170,  173,  178,  179,  187,  197,  202,  210,  213,  219,
         246,  252,  255,  267,  277,  279,  296,  308,  324,  332,  342,  348,
         351,  359,  364,  391,  392,  397,  399,  402,  404,  408,  420,  421,
         423,  427,  431,  433,  434,  436,  443,  453,  458,  459,  464,  465,
         466,  474,  488,  490,  493,  497,  502,  507,  519,  535,  539,  556,
         568,  577,  582,  583,  584,  585,  594,  607,  612,  619,  629,  635,
         638,  639,  652,  654,  657,  663,  668,  678,  680,  681,  684,  686,
         687,  693,  701,  703,  705,  720,  721,  731,  744,  747,  748,  757,
         761,  765,  767,  773,  774,  783,  786,  797,  800,  801,  804,  822,
         827,  828,  840,  859,  870,  876,  880,  883,  887,  903,  906,  908,
         912,  917,  921,  923,  928,  930,  941,  951,  954,  956,  959,  966,
         968,  976,  977,  986,  991,  997, 1006, 1009, 1011, 1012, 1019, 1021,
        1022], device='cuda:0')
train_iter preds : torch.Size([64, 29, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 29, 5], preds : 64, T, 29, 123]
train_iter preds w/view(-1, 123) : torch.Size([1856, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1856, 5])
[Step 0] --- GMM Debug ---
  NLL loss (mean): 1.8348
  pen state loss : 1.4586
  result0 max pdf: 8.4708
  result1 avg pre-log: 0.0473
  z_pi max: 0.4673, mean: 0.0500
  sigma1 min/max: 0.0424/29.4911
  sigma2 min/max: 0.0403/29.1004
  corr range: -0.9984 ~ 0.9991
iter:0 loss:15.890 ETA:36 days, 5:23:02.962799
 # _visualize_input_images_tb img_list: torch.Size([64, 30, 1, 64, 64])
 # _visualize_input_images_tb writer_id: torch.Size([64])
generate_square_subsequent_mask: torch.Size([31, 31])
[TransformerDecoder] *** forward: memory.shape=[1][B][torch.Size([60, 16, 512])], tgt.shape=[C][B][torch.Size([31, 16, 512])]
[TransformerDecoder] *** forward: output=[C][B][torch.Size([31, 16, 512])]
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 31]), unique : tensor([684, 783], device='cuda:0')
train_iter preds : torch.Size([64, 31, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 31, 5], preds : 64, T, 31, 123]
train_iter preds w/view(-1, 123) : torch.Size([1984, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1984, 5])
iter:1 loss:15.414 ETA:10 days, 18:47:25.217391
generate_square_subsequent_mask: torch.Size([26, 26])
[TransformerDecoder] *** forward: memory.shape=[1][B][torch.Size([60, 16, 512])], tgt.shape=[C][B][torch.Size([26, 16, 512])]
[TransformerDecoder] *** forward: output=[C][B][torch.Size([26, 16, 512])]
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 26]), unique : tensor([783], device='cuda:0')
train_iter preds : torch.Size([64, 26, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 26, 5], preds : 64, T, 26, 123]
train_iter preds w/view(-1, 123) : torch.Size([1664, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1664, 5])
iter:2 loss:18.188 ETA:1 day, 3:10:57.879520
generate_square_subsequent_mask: torch.Size([27, 27])
[TransformerDecoder] *** forward: memory.shape=[1][B][torch.Size([60, 16, 512])], tgt.shape=[C][B][torch.Size([27, 16, 512])]
[TransformerDecoder] *** forward: output=[C][B][torch.Size([27, 16, 512])]
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 27]), unique : tensor([783], device='cuda:0')
train_iter preds : torch.Size([64, 27, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 27, 5], preds : 64, T, 27, 123]
train_iter preds w/view(-1, 123) : torch.Size([1728, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1728, 5])
iter:3 loss:14.494 ETA:3 days, 3:05:16.217642
iter:4 loss:13.531 ETA:1 day, 11:20:03.399942
iter:5 loss:13.691 ETA:1 day, 4:32:22.487526
generate_square_subsequent_mask: torch.Size([25, 25])
[TransformerDecoder] *** forward: memory.shape=[1][B][torch.Size([60, 16, 512])], tgt.shape=[C][B][torch.Size([25, 16, 512])]
[TransformerDecoder] *** forward: output=[C][B][torch.Size([25, 16, 512])]
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 25]), unique : tensor([783], device='cuda:0')
train_iter preds : torch.Size([64, 25, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 25, 5], preds : 64, T, 25, 123]
train_iter preds w/view(-1, 123) : torch.Size([1600, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1600, 5])
iter:6 loss:12.406 ETA:1 day, 3:32:40.080528
generate_square_subsequent_mask: torch.Size([30, 30])
[TransformerDecoder] *** forward: memory.shape=[1][B][torch.Size([60, 16, 512])], tgt.shape=[C][B][torch.Size([30, 16, 512])]
[TransformerDecoder] *** forward: output=[C][B][torch.Size([30, 16, 512])]
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 30]), unique : tensor([783], device='cuda:0')
train_iter preds : torch.Size([64, 30, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 30, 5], preds : 64, T, 30, 123]
train_iter preds w/view(-1, 123) : torch.Size([1920, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1920, 5])
iter:7 loss:12.143 ETA:1 day, 1:57:17.834450
generate_square_subsequent_mask: torch.Size([43, 43])
[TransformerDecoder] *** forward: memory.shape=[1][B][torch.Size([60, 16, 512])], tgt.shape=[C][B][torch.Size([43, 16, 512])]
[TransformerDecoder] *** forward: output=[C][B][torch.Size([43, 16, 512])]
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 43]), unique : tensor([783], device='cuda:0')
train_iter preds : torch.Size([64, 43, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 43, 5], preds : 64, T, 43, 123]
train_iter preds w/view(-1, 123) : torch.Size([2752, 123]), gt_coords w/reshape(-1, 5) : torch.Size([2752, 5])
iter:8 loss:11.146 ETA:1 day, 5:10:01.350163
iter:9 loss:11.402 ETA:1 day, 4:12:32.303262
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 31]), unique : tensor([783], device='cuda:0')
iter:10 loss:10.793 ETA:1 day, 3:15:15.878720
generate_square_subsequent_mask: torch.Size([40, 40])
[TransformerDecoder] *** forward: memory.shape=[1][B][torch.Size([60, 16, 512])], tgt.shape=[C][B][torch.Size([40, 16, 512])]
[TransformerDecoder] *** forward: output=[C][B][torch.Size([40, 16, 512])]
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 40]), unique : tensor([783], device='cuda:0')
train_iter preds : torch.Size([64, 40, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 40, 5], preds : 64, T, 40, 123]
train_iter preds w/view(-1, 123) : torch.Size([2560, 123]), gt_coords w/reshape(-1, 5) : torch.Size([2560, 5])
iter:11 loss:10.142 ETA:2 days, 23:34:49.512058
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 29]), unique : tensor([783], device='cuda:0')
iter:12 loss:11.032 ETA:1 day, 3:33:57.781643
iter:13 loss:10.158 ETA:1 day, 3:23:35.911632
iter:14 loss:10.094 ETA:2 days, 18:47:32.241414
generate_square_subsequent_mask: torch.Size([23, 23])
[TransformerDecoder] *** forward: memory.shape=[1][B][torch.Size([60, 16, 512])], tgt.shape=[C][B][torch.Size([23, 16, 512])]
[TransformerDecoder] *** forward: output=[C][B][torch.Size([23, 16, 512])]
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 23]), unique : tensor([783], device='cuda:0')
train_iter preds : torch.Size([64, 23, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 23, 5], preds : 64, T, 23, 123]
train_iter preds w/view(-1, 123) : torch.Size([1472, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1472, 5])
iter:15 loss:10.544 ETA:1 day, 0:54:34.660844
iter:16 loss:10.185 ETA:1 day, 3:02:33.394272
generate_square_subsequent_mask: torch.Size([28, 28])
[TransformerDecoder] *** forward: memory.shape=[1][B][torch.Size([60, 16, 512])], tgt.shape=[C][B][torch.Size([28, 16, 512])]
[TransformerDecoder] *** forward: output=[C][B][torch.Size([28, 16, 512])]
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 28]), unique : tensor([783], device='cuda:0')
train_iter preds : torch.Size([64, 28, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 28, 5], preds : 64, T, 28, 123]
train_iter preds w/view(-1, 123) : torch.Size([1792, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1792, 5])
iter:17 loss:10.079 ETA:3 days, 2:28:22.171231
iter:18 loss:9.816 ETA:1 day, 2:12:17.269227
iter:19 loss:9.966 ETA:1 day, 6:21:14.209639
iter:20 loss:9.467 ETA:3 days, 4:12:24.234509
iter:21 loss:10.236 ETA:1 day, 0:53:58.166197
iter:22 loss:9.733 ETA:1 day, 2:36:16.178015
iter:23 loss:9.719 ETA:2 days, 20:52:46.714084
iter:24 loss:9.853 ETA:1 day, 5:18:34.403936
iter:25 loss:9.488 ETA:1 day, 2:48:44.235529
iter:26 loss:9.723 ETA:1 day, 0:53:31.132699
iter:27 loss:9.211 ETA:1 day, 0:33:53.008128
iter:28 loss:9.407 ETA:1 day, 7:40:51.012892
iter:29 loss:9.694 ETA:1 day, 2:34:52.680777
generate_square_subsequent_mask: torch.Size([33, 33])
[TransformerDecoder] *** forward: memory.shape=[1][B][torch.Size([60, 16, 512])], tgt.shape=[C][B][torch.Size([33, 16, 512])]
[TransformerDecoder] *** forward: output=[C][B][torch.Size([33, 16, 512])]
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 33]), unique : tensor([783], device='cuda:0')
train_iter preds : torch.Size([64, 33, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 33, 5], preds : 64, T, 33, 123]
train_iter preds w/view(-1, 123) : torch.Size([2112, 123]), gt_coords w/reshape(-1, 5) : torch.Size([2112, 5])
iter:30 loss:9.475 ETA:1 day, 2:02:09.977930
generate_square_subsequent_mask: torch.Size([32, 32])
[TransformerDecoder] *** forward: memory.shape=[1][B][torch.Size([60, 16, 512])], tgt.shape=[C][B][torch.Size([32, 16, 512])]
[TransformerDecoder] *** forward: output=[C][B][torch.Size([32, 16, 512])]
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 32]), unique : tensor([783], device='cuda:0')
train_iter preds : torch.Size([64, 32, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 32, 5], preds : 64, T, 32, 123]
train_iter preds w/view(-1, 123) : torch.Size([2048, 123]), gt_coords w/reshape(-1, 5) : torch.Size([2048, 5])
iter:31 loss:9.242 ETA:1 day, 2:48:12.113853
iter:32 loss:8.780 ETA:1 day, 3:51:45.098442
iter:33 loss:8.791 ETA:1 day, 4:45:04.170672
generate_square_subsequent_mask: torch.Size([36, 36])
[TransformerDecoder] *** forward: memory.shape=[1][B][torch.Size([60, 16, 512])], tgt.shape=[C][B][torch.Size([36, 16, 512])]
[TransformerDecoder] *** forward: output=[C][B][torch.Size([36, 16, 512])]
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 36]), unique : tensor([783], device='cuda:0')
train_iter preds : torch.Size([64, 36, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 36, 5], preds : 64, T, 36, 123]
train_iter preds w/view(-1, 123) : torch.Size([2304, 123]), gt_coords w/reshape(-1, 5) : torch.Size([2304, 5])
iter:34 loss:9.742 ETA:1 day, 2:01:21.523978
generate_square_subsequent_mask: torch.Size([22, 22])
[TransformerDecoder] *** forward: memory.shape=[1][B][torch.Size([60, 16, 512])], tgt.shape=[C][B][torch.Size([22, 16, 512])]
[TransformerDecoder] *** forward: output=[C][B][torch.Size([22, 16, 512])]
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 22]), unique : tensor([783], device='cuda:0')
train_iter preds : torch.Size([64, 22, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 22, 5], preds : 64, T, 22, 123]
train_iter preds w/view(-1, 123) : torch.Size([1408, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1408, 5])
iter:35 loss:8.985 ETA:1 day, 0:56:06.859843
iter:36 loss:9.406 ETA:1 day, 2:01:14.246211
iter:37 loss:9.762 ETA:1 day, 1:23:23.308588
iter:38 loss:8.674 ETA:1 day, 7:48:22.223445
iter:39 loss:8.624 ETA:1 day, 2:39:27.410558
iter:40 loss:8.403 ETA:2 days, 22:29:33.230791
iter:41 loss:8.328 ETA:1 day, 0:43:16.234529
iter:42 loss:9.547 ETA:1 day, 5:16:16.950284
generate_square_subsequent_mask: torch.Size([24, 24])
[TransformerDecoder] *** forward: memory.shape=[1][B][torch.Size([60, 16, 512])], tgt.shape=[C][B][torch.Size([24, 16, 512])]
[TransformerDecoder] *** forward: output=[C][B][torch.Size([24, 16, 512])]
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 24]), unique : tensor([783], device='cuda:0')
train_iter preds : torch.Size([64, 24, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 24, 5], preds : 64, T, 24, 123]
train_iter preds w/view(-1, 123) : torch.Size([1536, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1536, 5])
iter:43 loss:10.366 ETA:2 days, 23:30:52.150838
iter:44 loss:9.579 ETA:1 day, 2:08:42.297724
iter:45 loss:9.203 ETA:1 day, 1:15:45.995635
iter:46 loss:8.196 ETA:2 days, 22:20:41.358855
iter:47 loss:8.556 ETA:1 day, 8:37:14.935976
iter:48 loss:9.158 ETA:1 day, 0:59:36.931694
iter:49 loss:9.653 ETA:2 days, 23:14:27.053586
iter:50 loss:8.477 ETA:1 day, 3:15:48.216820
iter:51 loss:8.889 ETA:1 day, 2:54:57.015000
iter:52 loss:8.838 ETA:2 days, 19:19:19.932219
iter:53 loss:8.234 ETA:1 day, 5:16:41.662825
generate_square_subsequent_mask: torch.Size([52, 52])
[TransformerDecoder] *** forward: memory.shape=[1][B][torch.Size([60, 16, 512])], tgt.shape=[C][B][torch.Size([52, 16, 512])]
[TransformerDecoder] *** forward: output=[C][B][torch.Size([52, 16, 512])]
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 52]), unique : tensor([783], device='cuda:0')
train_iter preds : torch.Size([64, 52, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 52, 5], preds : 64, T, 52, 123]
train_iter preds w/view(-1, 123) : torch.Size([3328, 123]), gt_coords w/reshape(-1, 5) : torch.Size([3328, 5])
iter:54 loss:9.572 ETA:1 day, 2:05:15.895244
iter:55 loss:9.053 ETA:3 days, 0:32:17.893659
iter:56 loss:9.720 ETA:1 day, 1:30:36.527945
iter:57 loss:9.376 ETA:1 day, 3:57:15.544855
iter:58 loss:9.969 ETA:1 day, 3:07:57.411031
iter:59 loss:9.718 ETA:1 day, 2:28:24.356395
iter:60 loss:9.654 ETA:1 day, 8:46:57.877240
iter:61 loss:9.432 ETA:1 day, 0:44:25.748869
iter:62 loss:9.435 ETA:1 day, 4:40:37.229775
iter:63 loss:9.594 ETA:1 day, 2:02:21.681319
iter:64 loss:9.419 ETA:1 day, 4:04:57.361084
iter:65 loss:9.080 ETA:1 day, 3:36:19.274182
generate_square_subsequent_mask: torch.Size([37, 37])
[TransformerDecoder] *** forward: memory.shape=[1][B][torch.Size([60, 16, 512])], tgt.shape=[C][B][torch.Size([37, 16, 512])]
[TransformerDecoder] *** forward: output=[C][B][torch.Size([37, 16, 512])]
train_iter vq_loss.shape : torch.Size([4]), VQ codes : torch.Size([64, 37]), unique : tensor([783], device='cuda:0')
train_iter preds : torch.Size([64, 37, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 37, 5], preds : 64, T, 37, 123]
train_iter preds w/view(-1, 123) : torch.Size([2368, 123]), gt_coords w/reshape(-1, 5) : torch.Size([2368, 5])
