Filter the characters containing more than max_len points
number of training images:  50557
Filter the characters containing more than max_len points
Number of test images: 12634, Number of train images: 50557
Content_TR:: __init__ d_model: 512 , nhead: 2 , num_encoder_layers: 3 , dim_feedforward: 2048 , dropout: 0.1 , activation: relu , normalize_before: True
[TransformerDecoderLayer]: d_model=512, nhead=8, dim_feedforward=2048, dropout=0.1, activation=relu, normalize_before=True
TransformerDecoder:: __init__ decoder_layer: TransformerDecoderLayer(
  (self_attn): MultiheadAttention(
    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
  )
  (multihead_attn): MultiheadAttention(
    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
  )
  (linear1): Linear(in_features=512, out_features=2048, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
  (linear2): Linear(in_features=2048, out_features=512, bias=True)
  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout1): Dropout(p=0.1, inplace=False)
  (dropout2): Dropout(p=0.1, inplace=False)
  (dropout3): Dropout(p=0.1, inplace=False)
) , num_layers: 2 , norm: LayerNorm((512,), eps=1e-05, elementwise_affine=True) , return_intermediate: True
TransformerDecoder:: __init__ decoder_layer: TransformerDecoderLayer(
  (self_attn): MultiheadAttention(
    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
  )
  (multihead_attn): MultiheadAttention(
    (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
  )
  (linear1): Linear(in_features=512, out_features=2048, bias=True)
  (dropout): Dropout(p=0.1, inplace=False)
  (linear2): Linear(in_features=2048, out_features=512, bias=True)
  (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
  (dropout1): Dropout(p=0.1, inplace=False)
  (dropout2): Dropout(p=0.1, inplace=False)
  (dropout3): Dropout(p=0.1, inplace=False)
) , num_layers: 2 , norm: LayerNorm((512,), eps=1e-05, elementwise_affine=True) , return_intermediate: True
/home/jinsu0000/anaconda3/envs/sdt/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.
  warnings.warn(
/home/jinsu0000/anaconda3/envs/sdt/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
SDT_Generator::forward, style_imgs: torch.Size([16, 30, 1, 64, 64])
SDT_Generator::forward, batch_size: 16 , num_imgs: 30 , in_planes: 1 , h: 64 , w: 64
SDT_Generator::forward style_imgs.view(): torch.Size([480, 1, 64, 64])
SDT_Generator::forward Feat_Encoder_ResNet output: torch.Size([480, 512, 2, 2])
SDT_Generator::forward style_embe.view(): torch.Size([4, 480, 512])
SDT_Generator::forward base_encoder output memory: torch.Size([4, 480, 512])
SDT_Generator::forward WRITER memory: torch.Size([4, 480, 512]) , GLYPH memory: torch.Size([4, 480, 512])
SDT_Generator::forward rearrange writer_memory: torch.Size([4, 32, 15, 512]) , glyph_memory: torch.Size([4, 32, 15, 512])
SDT_Generator::forward [writer] memory_fea: torch.Size([60, 32, 512]) , compact_fea: torch.Size([32, 512])
SDT_Generator::forward [writer] pro_emb: torch.Size([32, 256])
SDT_Generator::forward [writer] query_emb: torch.Size([16, 256])
SDT_Generator::forward [writer] pos_emb: torch.Size([16, 256])
SDT_Generator::forward [writer] nce_emb: torch.Size([16, 2, 256])
SDT_Generator::forward [writer] normalize NCE nce_emb: torch.Size([16, 2, 256])
SDT_Generator::forward [glyph] patch_emb: torch.Size([4, 16, 15, 512])
SDT_Generator::forward [glyph] random_double_sampling result anc: torch.Size([16, 15, 1, 512]) , positive: torch.Size([16, 15, 1, 512]) , n_channels: 512
SDT_Generator::forward [glyph] anc reshape: torch.Size([16, 15, 512])
SDT_Generator::forward [glyph] anc_compact: torch.Size([16, 1, 512])
SDT_Generator::forward [glyph] anc_compact after pro_mlp_character: torch.Size([16, 1, 256])
SDT_Generator::forward [glyph] positive reshape: torch.Size([16, 15, 512])
SDT_Generator::forward [glyph] positive_compact: torch.Size([16, 1, 512])
SDT_Generator::forward [glyph] NCE anc_compact: torch.Size([16, 1, 256]) , positive_compact: torch.Size([16, 1, 256])
SDT_Generator::forward [glyph] normalize nce_emb_patch: torch.Size([16, 2, 256])
SDT_Generator::forward [KV] writer_style: torch.Size([60, 16, 512])
SDT_Generator::forward [KV] glyph_style: torch.Size([4, 16, 15, 512])
SDT_Generator::forward [KV] glyph_style rearranged: torch.Size([60, 16, 512])
SDT_Generator::forward [Decoder] seq: [16, T, 5] (T : length of the sequence)
SDT_Generator::forward [Decoder] seq_emb: [T, 16, 512]
Content_TR:: Feat_Encoder input: torch.Size([16, 1, 64, 64])
Content_TR:: Feat_Encoder Feat_Encoder(conv2d+resnet) output: torch.Size([16, 512, 2, 2])
Content_TR:: rearrange output: torch.Size([4, 16, 512])
Content_TR:: encoder output: torch.Size([4, 16, 512])
SDT_Generator::forward [Content Encoder] char_emb: [4, T, 16]
SDT_Generator::forward [Content Encoder] char_emb after mean: [T, 512]
SDT_Generator::forward [Content Encoder] char_emb after repeat: [1, T, 16]
SDT_Generator::forward [Decoder] tgt: [T, 16, 512] (T=T+1 : length of the sequence + 1 for content token)
generate_square_subsequent_mask: torch.Size([27, 27])
SDT_Generator::forward [Decoder] tgt after masking & add_position: [1+T, 16, 512]
[TransformerDecoder] *** forward: memory.shape=[1][B][512], tgt.shape=[C][B][512]
[TransformerDecoderLayer] *** forward_pre: memory.shape=[1][B][512], tgt.shape=[C][B][512]
[TransformerDecoderLayer] forward_pre tgt2.shape=[C][B][512] after self_attn
[TransformerDecoderLayer] forward_pre tgt.shape=[C][B][512] after sum with dropout1, norm2
[TransformerDecoderLayer] forward_pre tgt2.shape=[C][B][512] after multihead_attn
[TransformerDecoderLayer] *** forward_pre tgt.shape=[C][B][512] after linear
[TransformerDecoder] forward: layer[0] output.shape=[C][B][512]
[TransformerDecoder] forward: layer[1] output.shape=[C][B][512]
[TransformerDecoder] *** forward: output=[C][B][512]
SDT_Generator::forward [Writer Decoder] wri_hs: 2, T, 16, 512] (wri_dec_layers, T, B, C)
SDT_Generator::forward [Glyph Decoder] hs: [2, T, 16, 512] (gly_dec_layers, T, B, C)
SDT_Generator::forward [Decoder] h after transpose: 16, T, 512] (B, T, C)
SDT_Generator::forward [Decoder Output] pred_sequence: [16, T, 123] (B, T, C)
train_iter preds : torch.Size([64, 27, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 27, 5], preds : 64, T, 27, 123]
train_iter preds w/view(-1, 123) : torch.Size([1728, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1728, 5])
[Step 0] --- GMM Debug ---
  NLL loss (mean): 1.7940
  pen state loss : 1.2306
  result0 max pdf: 21.4724
  result1 avg pre-log: 0.0633
  z_pi max: 0.5873, mean: 0.0500
  sigma1 min/max: 0.0232/30.6030
  sigma2 min/max: 0.0361/30.2590
  corr range: -0.9941 ~ 0.9992
iter:0 loss:15.592 ETA:33 days, 6:52:34.389572
 # _visualize_input_images_tb img_list: torch.Size([64, 30, 1, 64, 64])
 # _visualize_input_images_tb writer_id: torch.Size([64])
generate_square_subsequent_mask: torch.Size([34, 34])
train_iter preds : torch.Size([64, 34, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 34, 5], preds : 64, T, 34, 123]
train_iter preds w/view(-1, 123) : torch.Size([2176, 123]), gt_coords w/reshape(-1, 5) : torch.Size([2176, 5])
iter:1 loss:19.617 ETA:13 days, 4:51:40.358787
generate_square_subsequent_mask: torch.Size([25, 25])
train_iter preds : torch.Size([64, 25, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 25, 5], preds : 64, T, 25, 123]
train_iter preds w/view(-1, 123) : torch.Size([1600, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1600, 5])
iter:2 loss:15.010 ETA:1 day, 3:13:02.618873
iter:3 loss:13.298 ETA:1 day, 1:18:29.101254
generate_square_subsequent_mask: torch.Size([29, 29])
train_iter preds : torch.Size([64, 29, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 29, 5], preds : 64, T, 29, 123]
train_iter preds w/view(-1, 123) : torch.Size([1856, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1856, 5])
iter:4 loss:11.698 ETA:1 day, 1:59:25.786118
iter:5 loss:11.477 ETA:1 day, 7:50:22.016122
generate_square_subsequent_mask: torch.Size([37, 37])
train_iter preds : torch.Size([64, 37, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 37, 5], preds : 64, T, 37, 123]
train_iter preds w/view(-1, 123) : torch.Size([2368, 123]), gt_coords w/reshape(-1, 5) : torch.Size([2368, 5])
iter:6 loss:11.875 ETA:23:21:30.189621
generate_square_subsequent_mask: torch.Size([45, 45])
train_iter preds : torch.Size([64, 45, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 45, 5], preds : 64, T, 45, 123]
train_iter preds w/view(-1, 123) : torch.Size([2880, 123]), gt_coords w/reshape(-1, 5) : torch.Size([2880, 5])
iter:7 loss:10.821 ETA:1 day, 0:23:41.175419
iter:8 loss:10.498 ETA:1 day, 0:59:54.931400
iter:9 loss:10.565 ETA:1 day, 2:37:50.901146
generate_square_subsequent_mask: torch.Size([26, 26])
train_iter preds : torch.Size([64, 26, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 26, 5], preds : 64, T, 26, 123]
train_iter preds w/view(-1, 123) : torch.Size([1664, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1664, 5])
iter:10 loss:10.894 ETA:1 day, 2:21:20.700369
iter:11 loss:10.818 ETA:1 day, 2:11:01.277671
generate_square_subsequent_mask: torch.Size([28, 28])
train_iter preds : torch.Size([64, 28, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 28, 5], preds : 64, T, 28, 123]
train_iter preds w/view(-1, 123) : torch.Size([1792, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1792, 5])
iter:12 loss:10.833 ETA:1 day, 1:01:58.055269
iter:13 loss:11.253 ETA:1 day, 2:38:10.010793
generate_square_subsequent_mask: torch.Size([32, 32])
train_iter preds : torch.Size([64, 32, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 32, 5], preds : 64, T, 32, 123]
train_iter preds w/view(-1, 123) : torch.Size([2048, 123]), gt_coords w/reshape(-1, 5) : torch.Size([2048, 5])
iter:14 loss:10.203 ETA:1 day, 1:14:48.908632
generate_square_subsequent_mask: torch.Size([23, 23])
train_iter preds : torch.Size([64, 23, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 23, 5], preds : 64, T, 23, 123]
train_iter preds w/view(-1, 123) : torch.Size([1472, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1472, 5])
iter:15 loss:10.471 ETA:1 day, 1:29:03.597459
iter:16 loss:9.953 ETA:1 day, 1:22:32.735676
iter:17 loss:10.948 ETA:1 day, 8:41:24.850674
iter:18 loss:9.934 ETA:2 days, 15:04:01.742062
iter:19 loss:9.132 ETA:1 day, 2:54:33.997695
generate_square_subsequent_mask: torch.Size([24, 24])
train_iter preds : torch.Size([64, 24, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 24, 5], preds : 64, T, 24, 123]
train_iter preds w/view(-1, 123) : torch.Size([1536, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1536, 5])
iter:20 loss:9.611 ETA:1 day, 1:09:39.749179
iter:21 loss:10.689 ETA:2 days, 16:10:37.673922
generate_square_subsequent_mask: torch.Size([30, 30])
train_iter preds : torch.Size([64, 30, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 30, 5], preds : 64, T, 30, 123]
train_iter preds w/view(-1, 123) : torch.Size([1920, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1920, 5])
iter:22 loss:9.441 ETA:1 day, 1:11:28.932879
generate_square_subsequent_mask: torch.Size([48, 48])
train_iter preds : torch.Size([64, 48, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 48, 5], preds : 64, T, 48, 123]
train_iter preds w/view(-1, 123) : torch.Size([3072, 123]), gt_coords w/reshape(-1, 5) : torch.Size([3072, 5])
iter:23 loss:8.941 ETA:1 day, 1:19:17.633190
generate_square_subsequent_mask: torch.Size([43, 43])
train_iter preds : torch.Size([64, 43, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 43, 5], preds : 64, T, 43, 123]
train_iter preds w/view(-1, 123) : torch.Size([2752, 123]), gt_coords w/reshape(-1, 5) : torch.Size([2752, 5])
iter:24 loss:8.767 ETA:2 days, 12:11:47.304609
generate_square_subsequent_mask: torch.Size([31, 31])
train_iter preds : torch.Size([64, 31, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 31, 5], preds : 64, T, 31, 123]
train_iter preds w/view(-1, 123) : torch.Size([1984, 123]), gt_coords w/reshape(-1, 5) : torch.Size([1984, 5])
iter:25 loss:9.254 ETA:1 day, 3:12:28.179370
iter:26 loss:9.478 ETA:1 day, 2:43:06.148350
iter:27 loss:9.688 ETA:2 days, 14:32:07.579824
iter:28 loss:9.303 ETA:1 day, 8:35:44.733530
iter:29 loss:8.553 ETA:1 day, 1:55:02.070587
iter:30 loss:8.849 ETA:2 days, 15:31:54.676757
iter:31 loss:9.192 ETA:1 day, 2:32:44.475600
iter:32 loss:9.040 ETA:1 day, 2:16:35.171951
iter:33 loss:9.436 ETA:2 days, 16:22:17.422298
generate_square_subsequent_mask: torch.Size([53, 53])
train_iter preds : torch.Size([64, 53, 123]), nce_emb : torch.Size([64, 2, 256]), nce_emb_patch : torch.Size([64, 2, 256])
train_iter GT coords : 64, T, 53, 5], preds : 64, T, 53, 123]
train_iter preds w/view(-1, 123) : torch.Size([3392, 123]), gt_coords w/reshape(-1, 5) : torch.Size([3392, 5])
